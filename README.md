# Be More Agent ğŸ¤–
**A Customizable, Offline-First AI Agent for Raspberry Pi**

[![Watch the Demo](https://img.youtube.com/vi/l5ggH-YhuAw/maxresdefault.jpg)](https://youtu.be/l5ggH-YhuAw)

![Python](https://img.shields.io/badge/Python-3.9%2B-blue) ![Platform](https://img.shields.io/badge/Platform-Raspberry%20Pi-red) ![License](https://img.shields.io/badge/License-MIT-green)

This project turns a Raspberry Pi into a fully functional, conversational AI agent. Unlike cloud-based assistants, this agent runs **100% locally** on your device. It listens for a wake word, processes speech, "thinks" using a local Large Language Model (LLM), and speaks back with a low-latency neural voiceâ€”all while displaying reactive face animations.

**It is designed as a blank canvas:** You can easily swap the face images and sound effects to create your own character!

## âœ¨ Features

* **100% Local Intelligence**: Powered by **Ollama** (LLM) and **Whisper.cpp** (Speech-to-Text). No API fees, no cloud data usage.
* **Open Source Wake Word**: Wakes up to your custom model using **OpenWakeWord** (Offline & Free). No access keys required.
* **Hardware-Aware Audio**: Automatically detects your microphone's sample rate and resamples audio on the fly to prevent ALSA errors.
* **Smart Web Search**: Uses DuckDuckGo to find real-time news and information when the LLM doesn't know the answer.
* **Reactive Faces**: The GUI updates the character's face based on its state (Listening, Thinking, Speaking, Idle).
* **Fast Text-to-Speech**: Uses **Piper TTS** for low-latency, high-quality voice generation on the Pi.
* **Vision Capable**: Can "see" and describe the world using a connected camera and the **Moondream** vision model.

## ğŸ› ï¸ Hardware Requirements

* **Raspberry Pi 5** (Recommended) or Pi 4 (4GB RAM minimum) - i used Raspberry Pi 5 (16GB)
* USB Microphone & Speaker
* LCD Screen (DSI or HDMI) - i used Freenove 5-inch touchscreen display
* Raspberry Pi Camera Module - i used Raspberry Pi Camera Module v2

## ğŸ”§ Additional Hardware: 
* Pimoroni NVMe Base Duo
* Geekworm X1203 5V UPS shield
* Adafruit Feather 32u4 Basic Proto
* 3.7V lithium ion battery
* 6mm momentary switches x 7
* 5x2mm round magnets x 16

---

## ğŸ“‚ Project Structure

```text
be-more-agent/
â”œâ”€â”€ agent.py                   # The main brain script
â”œâ”€â”€ setup.sh                   # Auto-installer script
â”œâ”€â”€ config.json                # User settings (Models, Prompt, Hardware)
â”œâ”€â”€ chat_memory.json           # Conversation history
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ whisper.cpp/               # Speech-to-Text engine
â”œâ”€â”€ piper/                     # Piper TTS engine & voice models
â”œâ”€â”€ models/                    # ONNX models
â”‚   â”œâ”€â”€ wakeword.onnx          # OpenWakeWord model 
â”œâ”€â”€ stl/                       # Case files for 3d printing
â”œâ”€â”€ pcb/                       # PCB file
â”œâ”€â”€ sounds/                    # Sound effects folder
â”‚   â”œâ”€â”€ greeting_sounds/       # Startup .wav files
â”‚   â”œâ”€â”€ thinking_sounds/       # Looping .wav files
â”‚   â”œâ”€â”€ ack_sounds/            # "I heard you" .wav files
â”‚   â””â”€â”€ error_sounds/          # Error/Confusion .wav files
â””â”€â”€ faces/                     # Face images folder
    â”œâ”€â”€ idle/                  # .png sequence for idle state
    â”œâ”€â”€ listening/             # .png sequence for listening
    â”œâ”€â”€ thinking/              # .png sequence for thinking
    â”œâ”€â”€ speaking/              # .png sequence for speaking
    â”œâ”€â”€ error/                 # .png sequence for errors
    â””â”€â”€ warmup/                # .png sequence for startup
```

---

## ğŸš€ Installation

### 1. Prerequisites
Ensure your Raspberry Pi OS is up to date.
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install git -y
```

### 2. Install Ollama
This agent relies on [Ollama](https://ollama.com) to run the brain.
```bash
curl -fsSL https://ollama.com/install.sh| sh
```
*Pull the required models:*
```bash
ollama pull gemma3:1b
ollama pull moondream
```

### 3. Clone & Setup
```bash
git clone https://github.com/tzirulnicov/be-more-agent.git
cd be-more-agent
chmod +x setup.sh
./setup.sh
```
*The setup script will install system libraries, create necessary folders, download Piper TTS, and set up the Python virtual environment.*

### 4. Configure the Wake Word
The setup script downloads a default wake word ("Hey Jarvis"). To use your own:
1. Train a model at [OpenWakeWord](https://github.com/dscripka/openWakeWord).
2. Place the `.onnx` file in the root folder.
3. Rename it to `wakeword.onnx`.

### 5. Run the Agent
```bash
source venv/bin/activate
python agent.py
```

---

## ğŸ“‚ Configuration (`config.json`)

You can modify the hardware behavior and personality in `config.json`. The `agent.py` script creates this on the first run if it doesn't exist, but you can create it manually:

```json
{
    "text_model": "gemma3:1b",
    "vision_model": "moondream",
    "voice_model": "piper/en_GB-semaine-medium.onnx",
    "chat_memory": true,
    "camera_rotation": 0,
    "system_prompt_extras": "You are a helpful robot assistant. Keep responses short and cute."
}
```

---

## ğŸ¨ Customizing Your Character

This software is a generic framework. You can give it a new personality by replacing the assets:

1.  **Faces:** The script looks for PNG sequences in `faces/[state]/`. It will loop through all images found in the folder.
2.  **Sounds:** Put multiple `.wav` files in the `sounds/[category]/` folders. The robot will pick one at random each time (e.g., different "thinking" hums or "error" buzzes).

---

## âš ï¸ Troubleshooting

* **"No search library found":** If web search fails, ensure you are in the virtual environment and `duckduckgo-search` is installed via pip.
* **Shutdown Errors:** When you exit the script (Ctrl+C), you might see `Expression 'alsa_snd_pcm_mmap_begin' failed`. **This is normal.** It just means the audio stream was cut off mid-sample. It does not affect the functionality.
* **Audio Glitches:** If the voice sounds fast or slow, the script attempts to auto-detect sample rates. Ensure your `config.json` points to a valid `.onnx` voice model in the `piper/` folder.

## ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.

## âš–ï¸ Legal Disclaimer
**"BMO"** and **"Adventure Time"** are trademarks of **Cartoon Network** (Warner Bros. Discovery).

This project is a **fan creation** built for educational and hobbyist purposes only. It is **not** affiliated with, endorsed by, or connected to Cartoon Network or the official Adventure Time brand in any way. The software provided here is a generic agent framework; users are responsible for the assets they load into it.
